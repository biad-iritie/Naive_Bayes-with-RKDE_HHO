{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing our novel approach with Naive Bayes\n",
    "\n",
    "> Preprocessing: Clean and preprocess your dataset. This may include handling missing values, encoding categorical variables, and scaling features.\n",
    "\n",
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/biad/Desktop/THESIS/Tests/RKDE_HHO/libs/../data/banana/banana\n",
      "Loaded banana data: 5300 samples, 2 dimensions, 2 labels\n",
      "classes = {1.0, -1.0}\n"
     ]
    }
   ],
   "source": [
    "from libs import data\n",
    "from libs import kde_lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from libs.exp_lib import Density_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "X0, y0 = data.load_data(\"banana\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X0, y0, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Get the dimension of our data\\ndim = X_train.ndim\\n\\n# Calculate the number of classes and features\\nclasses = np.unique(y_train)\\nn_features = X_train.shape[1]\\n\\n# Initialize robust densities\\nrobust_densities = np.zeros((len(X_train), dim))\\n\\nprint(robust_densities.shape)\\nkernel = 'gaussian'\\n#h = .5 \""
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Get the dimension of our data\n",
    "dim = X_train.ndim\n",
    "\n",
    "# Calculate the number of classes and features\n",
    "classes = np.unique(y_train)\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "# Initialize robust densities\n",
    "robust_densities = np.zeros((len(X_train), dim))\n",
    "\n",
    "print(robust_densities.shape)\n",
    "kernel = 'gaussian'\n",
    "#h = .5 \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 - step3 : Robust Kernel Density Estimation (RKDE) & Bandwidth Selection using HHO:\n",
    "\n",
    "- Implement the RKDE algorithm with IRLS and Robust M-estimation (Hampel function) for each class.\n",
    "- Calculate robust densities for each class based on the RKDE algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' for class_label in classes:\\n    # GET for each class\\n    class_indices = np.where(y_train==class_label)[0]\\n    class_X = X_train[class_indices]\\n    h = kde_lib.hho_bandwith_selection(class_X,class_X)\\n    #h = .5\\n    # Get for each feature\\n    rkde_feature =[]\\n    for d in range(dim):\\n        X = class_X[:,d] \\n        X = X[:,np.newaxis]\\n        #print(X.shape)\\n        model = Density_model(\"rkde\", \"banana\", 0,kernel,h)\\n        model.fit(X,X,grid=None)\\n        rkde = model.density\\n        \\n        robust_densities[class_indices,d] = rkde[:,0] '"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\" for class_label in classes:\n",
    "    # GET for each class\n",
    "    class_indices = np.where(y_train==class_label)[0]\n",
    "    class_X = X_train[class_indices]\n",
    "    h = kde_lib.hho_bandwith_selection(class_X,class_X)\n",
    "    #h = .5\n",
    "    # Get for each feature\n",
    "    rkde_feature =[]\n",
    "    for d in range(dim):\n",
    "        X = class_X[:,d] \n",
    "        X = X[:,np.newaxis]\n",
    "        #print(X.shape)\n",
    "        model = Density_model(\"rkde\", \"banana\", 0,kernel,h)\n",
    "        model.fit(X,X,grid=None)\n",
    "        rkde = model.density\n",
    "        \n",
    "        robust_densities[class_indices,d] = rkde[:,0] \"\"\"\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: Incorporating RKDE into Naive Bayes:\n",
    "\n",
    "> - Modify Naive Bayes classifier to use the RKDE densities instead of traditional Gaussian densities.\n",
    "> - For prediction, calculate the likelihood using the robust densities obtained from RKDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustNaiveBayes(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.class_priors = None\n",
    "        #self.robust_densities = None\n",
    "        self.kernel = 'gaussian'\n",
    "        self.classifiers = {}  # Store GaussianNB classifiers for each class\n",
    "        self.robust_densities = {}  # Store robust densities for each class\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the robust Naive Bayes model with RKDE densities.\n",
    "\n",
    "        Parameters:\n",
    "        X (array-like): Training data features.\n",
    "        y (array-like): Training data labels.\n",
    "        \"\"\"\n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "\n",
    "        # Calculate class priors\n",
    "        self.class_priors = np.array([np.mean(y==c) for c in self.classes])\n",
    "\n",
    "        # Initialize robust densities\n",
    "        #robust_densities = np.zeros((n_samples, n_features))\n",
    "        #robust_densities = np.zeros(n_samples)\n",
    "\n",
    "        for class_label in self.classes :\n",
    "            # GET for each class\n",
    "            class_indices = np.where(y==class_label)[0]\n",
    "            class_data = X[class_indices]\n",
    "\n",
    "            self.classifiers[class_label] = GaussianNB()\n",
    "            self.classifiers[class_label].fit(class_data,y[class_indices])\n",
    "            X_plot = np.linspace(np.min(class_data),np.max(class_data),len(class_data))\n",
    "            bandwidth = kde_lib.hho_bandwith_selection(class_data,class_data)\n",
    "            #bandwidth = .955\n",
    "            model = Density_model(\"rkde\",\"banana\",0,self.kernel,bandwidth)\n",
    "            model.fit(class_data, class_data, grid=None)\n",
    "            rkde = model.density \n",
    "\n",
    "            self.robust_densities[class_label] = rkde[:,0]\n",
    "            \"\"\" self.robust_densities[class_label] = np.zeros((len(class_data),n_features))\n",
    "            # Get for each feature\n",
    "            for feature in range(n_features):\n",
    "                feature_data = class_data[:,feature]\n",
    "                feature_data = feature_data[:,np.newaxis]\n",
    "                #X_plot = np.linspace(np.min(feature_data),np.max(feature_data),len(feature_data))\n",
    "                #X_plot = X_plot[:,np.newaxis] \n",
    "                #bandwidth = kde_lib.hho_bandwith_selection(feature_data,feature_data)\n",
    "                #print(feature_data.shape)\n",
    "                #X_plot = X_plot[:,np.newaxis]\n",
    "                #print(X_plot.shape)\n",
    "                model = Density_model(\"rkde\",\"banana\",0,self.kernel,bandwidth)\n",
    "                model.fit(feature_data, feature_data, grid=None)\n",
    "                rkde = model.density\n",
    "                #print(robust_densities[class_indices,feature])\n",
    "                #robust_densities[class_indices,feature] = rkde[:,0]\n",
    "                self.robust_densities[class_label][:,feature] = rkde[:,0] \"\"\"\n",
    "        #self.robust_densities = np.array(robust_densities)\n",
    "\n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels and RKDE likelihoods for input data.\n",
    "\n",
    "        Parameters:\n",
    "        X (array-like): Input data features.\n",
    "\n",
    "        Returns:\n",
    "        y_pred (array-like): Predicted class labels.\n",
    "        rkde_likelihoods (array-like): RKDE likelihoods for each class.\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        n_classes = len(self.classes)\n",
    "        predictions = []\n",
    "\n",
    "        \"\"\" for sample in X:\n",
    "            likelihoods = []\n",
    "\n",
    "            for class_label in self.classes:\n",
    "                classifier = self.classifiers[class_label]\n",
    "                robust_density = self.robust_densities[class_label]\n",
    "                # Calculate the likelihood using the robust density and GaussianNB classifier\n",
    "                log_likelihood = classifier.predict_joint_log_proba(sample.reshape(1, -1))\n",
    "                likelihood = np.prod(np.exp(log_likelihood * robust_density)) \n",
    "                likelihoods.append(likelihood)\n",
    "\n",
    "            predicted_class = np.argmax(likelihoods)\n",
    "            predictions.append(self.classes[predicted_class]) \"\"\"\n",
    "        for sample in X:\n",
    "\n",
    "            likelihoods = []\n",
    "\n",
    "            # Calculate likelihood for each class\n",
    "            for class_label in self.classes:\n",
    "                # GET for each class\n",
    "                #class_indices = np.where(self.y_train == class_label)[0]\n",
    "                density = self.robust_densities[class_label]\n",
    "                likelihoods.append(np.prod(norm.pdf(sample, loc=density.mean(), scale=density.std())))\n",
    "            \n",
    "            # Normalize likelihoods using class priors\n",
    "            normalized_likelihoods = likelihoods * self.class_priors\n",
    "\n",
    "            # Predict the class with the highest normalized likelihood\n",
    "            predicted_class = np.argmax(normalized_likelihoods)\n",
    "            predictions.append(self.classes[predicted_class])\n",
    "        \n",
    "        return np.array(predictions)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' classifier = RobustNaiveBayes()\\nclassifier.fit(X_train, y_train)\\n\\nnormal_NB = GaussianNB()\\nnormal_NB.fit(X_train, y_train) '"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit the RobustNaiveBayes classifier\n",
    "\"\"\" classifier = RobustNaiveBayes()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "normal_NB = GaussianNB()\n",
    "normal_NB.fit(X_train, y_train) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3710, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of our train data and the robust densities\n",
    "print(X_train.shape)\n",
    "#print(classifier.robust_densities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' y_pred = classifier.predict(X_test)\\nprint(np.unique(y_pred))\\n\\nnormal_NB_pred = normal_NB.predict(X_test)\\nprint(np.unique(normal_NB_pred))\\n\\n# Calculate accuracy\\naccuracy = accuracy_score(y_test, y_pred)\\nprecision = precision_score(y_test, y_pred)\\nrecall = recall_score(y_test, y_pred)\\nf1 = f1_score(y_test, y_pred)\\nprint(\"Accuracy 1:\", accuracy)\\nprint(\"precision 1:\", precision)\\nprint(\"recall 1:\", recall)\\nprint(\"f1 1:\", f1)\\n\\naccuracy = accuracy_score(y_test, normal_NB_pred)\\nprecision = precision_score(y_test, normal_NB_pred)\\nrecall = recall_score(y_test, normal_NB_pred)\\nf1 = f1_score(y_test, normal_NB_pred)\\nprint(\"Accuracy 2:\", accuracy)\\nprint(\"precision 2:\", precision)\\nprint(\"recall 2:\", recall)\\nprint(\"f1 2:\", f1) '"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "\"\"\" y_pred = classifier.predict(X_test)\n",
    "print(np.unique(y_pred))\n",
    "\n",
    "normal_NB_pred = normal_NB.predict(X_test)\n",
    "print(np.unique(normal_NB_pred))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Accuracy 1:\", accuracy)\n",
    "print(\"precision 1:\", precision)\n",
    "print(\"recall 1:\", recall)\n",
    "print(\"f1 1:\", f1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, normal_NB_pred)\n",
    "precision = precision_score(y_test, normal_NB_pred)\n",
    "recall = recall_score(y_test, normal_NB_pred)\n",
    "f1 = f1_score(y_test, normal_NB_pred)\n",
    "print(\"Accuracy 2:\", accuracy)\n",
    "print(\"precision 2:\", precision)\n",
    "print(\"recall 2:\", recall)\n",
    "print(\"f1 2:\", f1) \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers Comparaison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2700x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_circles, make_moons, make_classification\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    \"Naive Bayes\" : GaussianNB(),\n",
    "    #\"Robust Naive Bayes\": RobustNaiveBayes(),\n",
    "}\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [\n",
    "    make_moons(noise=0.3, random_state=0),\n",
    "    make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "    linearly_separable,\n",
    "]\n",
    "datasets_name = [\n",
    "    \"make_moons\",\n",
    "    \"make_circles \",\n",
    "    \"make_classification\"\n",
    "]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num must be an integer with 1 <= num <= 6, not 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [318], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m cm \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mRdBu\n\u001b[1;32m     10\u001b[0m cm_bright \u001b[38;5;241m=\u001b[39m ListedColormap([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#FF0000\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#0000FF\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclassifiers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ds_cnt \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     13\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/data_science/lib/python3.9/site-packages/matplotlib/pyplot.py:1323\u001b[0m, in \u001b[0;36msubplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m fig \u001b[39m=\u001b[39m gcf()\n\u001b[1;32m   1322\u001b[0m \u001b[39m# First, search for an existing subplot with a matching spec.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m key \u001b[39m=\u001b[39m SubplotSpec\u001b[39m.\u001b[39;49m_from_subplot_args(fig, args)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m fig\u001b[39m.\u001b[39maxes:\n\u001b[1;32m   1326\u001b[0m     \u001b[39m# if we found an Axes at the position sort out if we can re-use it\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     \u001b[39mif\u001b[39;00m ax\u001b[39m.\u001b[39mget_subplotspec() \u001b[39m==\u001b[39m key:\n\u001b[1;32m   1328\u001b[0m         \u001b[39m# if the user passed no kwargs, re-use\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/data_science/lib/python3.9/site-packages/matplotlib/gridspec.py:598\u001b[0m, in \u001b[0;36mSubplotSpec._from_subplot_args\u001b[0;34m(figure, args)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    597\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(num, Integral) \u001b[39mor\u001b[39;00m num \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m num \u001b[39m>\u001b[39m rows\u001b[39m*\u001b[39mcols:\n\u001b[0;32m--> 598\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    599\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnum must be an integer with 1 <= num <= \u001b[39m\u001b[39m{\u001b[39;00mrows\u001b[39m*\u001b[39mcols\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnot \u001b[39m\u001b[39m{\u001b[39;00mnum\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m         )\n\u001b[1;32m    602\u001b[0m     i \u001b[39m=\u001b[39m j \u001b[39m=\u001b[39m num\n\u001b[1;32m    603\u001b[0m \u001b[39mreturn\u001b[39;00m gs[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:j]\n",
      "\u001b[0;31mValueError\u001b[0m: num must be an integer with 1 <= num <= 6, not 7"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) +1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "    # Plot the testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors=\"k\")\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in classifiers.items():\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "\n",
    "        clf = make_pipeline(StandardScaler(), clf)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        DecisionBoundaryDisplay.from_estimator(\n",
    "            clf, X, cmap=cm, alpha=.8, ax=ax, eps=.5\n",
    "        )\n",
    "        # Plot the training points\n",
    "        ax.scatter(\n",
    "            X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\"\n",
    "        )\n",
    "        # Plot the testing points\n",
    "        ax.scatter(\n",
    "            X_test[:, 0],\n",
    "            X_test[:, 1],\n",
    "            c=y_test,\n",
    "            cmap=cm_bright,\n",
    "            edgecolors=\"k\",\n",
    "            alpha=0.6,\n",
    "        )\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        ax.text(\n",
    "            x_max - 0.3,\n",
    "            y_min + 0.3,\n",
    "            (\"%.2f\" % accuracy).lstrip(\"0\"),\n",
    "            size=10,\n",
    "            horizontalalignment=\"right\",\n",
    "        )\n",
    "        i += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "643985f69f89cfee59ccb9ceb257d9cb58c13bdd97c74d508c0964730dccc282"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
